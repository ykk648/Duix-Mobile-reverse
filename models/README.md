# ğŸ§  æ¨¡å‹å¤ç°ä»£ç 

æœ¬ç›®å½•åŒ…å« DUIX æ•°å­—äººæ¨¡å‹çš„ PyTorch å¤ç°ç‰ˆæœ¬ã€‚

## ğŸ“ æ–‡ä»¶è¯´æ˜

| æ–‡ä»¶ | æè¿° | æ¨èåº¦ |
|------|------|--------|
| **`MobileNet_Fixed.py`** | âœ… **PyTorch å¤ç°æ¨¡å‹** | â­â­â­â­â­ |

## ğŸš€ å¿«é€Ÿä½¿ç”¨

```python
from MobileNet_Fixed import MobileNetV2Unet
import torch

# åˆ›å»ºæ¨¡å‹
model = MobileNetV2Unet(use_groupnorm=False)
model.eval()

# è¾“å…¥
audio = torch.randn(1, 256, 20)      # éŸ³é¢‘ç‰¹å¾
face = torch.randn(1, 6, 160, 160)   # 6é€šé“äººè„¸å›¾åƒ

# æ¨ç†
with torch.no_grad():
    output = model(face, audio)

print(f"è¾“å‡º: {output.shape}")        # [1, 3, 160, 160]
print(f"èŒƒå›´: [{output.min():.2f}, {output.max():.2f}]")  # [-1, 1]
```

## ğŸ“Š æ¨¡å‹å‚æ•°

| ç»„ä»¶ | å‚æ•°é‡ |
|------|--------|
| Image Encoder (MobileNetV2) | 1.92M |
| Audio Encoder | 0.55M |
| U-Net Decoder | 2.06M |
| **æ€»è®¡** | **4.53M** |

## âœ… æ¨¡å‹ç‰¹ç‚¹

### MobileNet_Fixed.py

- âœ… è¾“å‡ºæ¿€æ´»å‡½æ•°æ­£ç¡® (TanH)
- âœ… éŸ³é¢‘ç¼–ç å™¨å®Œæ•´ (8å±‚)
- âœ… ç»“æ„ä¸ NCNN å¯¹é½ (~95%)
- âœ… å¯ç›´æ¥ç”¨äºè®­ç»ƒ/æ¨ç†

## ğŸ”§ é…ç½®é€‰é¡¹

```python
# ä½¿ç”¨ BatchNormï¼ˆæ¨èç”¨äºè®­ç»ƒï¼‰
model = MobileNetV2Unet(use_groupnorm=False)

# ä½¿ç”¨ GroupNormï¼ˆå®Œå…¨å¯¹é½ NCNNï¼‰
model = MobileNetV2Unet(use_groupnorm=True)
```

## ğŸ“¥ è¾“å…¥æ ¼å¼

### éŸ³é¢‘ç‰¹å¾

```python
# å½¢çŠ¶: [B, 256, 20]
# - B: batch size
# - 256: ç‰¹å¾ç»´åº¦ï¼ˆå¦‚ Wenet è¾“å‡ºï¼‰
# - 20: æ—¶é—´æ­¥æ•°

audio = torch.randn(batch_size, 256, 20)
```

### äººè„¸å›¾åƒ

```python
# å½¢çŠ¶: [B, 6, H, W]
# - B: batch size
# - 6: é€šé“æ•° = å½“å‰å¸§(3) + å‚è€ƒå¸§(3)
# - H, W: å›¾åƒå°ºå¯¸ï¼ˆé€šå¸¸ 160x160ï¼‰

# å›¾åƒå½’ä¸€åŒ–åˆ° [-1, 1]
current_frame = (current_frame / 255.0) * 2 - 1   # [3, H, W]
reference_frame = (reference_frame / 255.0) * 2 - 1  # [3, H, W]
face = torch.cat([current_frame, reference_frame], dim=0)  # [6, H, W]
```

## ğŸ“¤ è¾“å‡ºæ ¼å¼

```python
# å½¢çŠ¶: [B, 3, H, W]
# èŒƒå›´: [-1, 1] (TanH æ¿€æ´»)

output = model(face, audio)

# è½¬æ¢ä¸ºå›¾åƒ
output_image = (output + 1) / 2 * 255  # [0, 255]
output_image = output_image.clamp(0, 255).byte()
```

## ğŸ§ª æµ‹è¯•æ¨¡å‹

```bash
cd models
python MobileNet_Fixed.py
```

è¾“å‡ºç¤ºä¾‹ï¼š
```
==================================================
æµ‹è¯•ä¿®æ­£åçš„æ¨¡å‹
==================================================
Audio input shape: torch.Size([1, 256, 20])
Face input shape: torch.Size([1, 6, 160, 160])

Output shape: torch.Size([1, 3, 160, 160])
Output range: [-0.35, 0.42]
Expected range: [-1, 1] (TanH)

Total parameters: 4.53M
Expected: ~3.77M (NCNN model)

==================================================
âœ… æ¨¡å‹æµ‹è¯•å®Œæˆ
==================================================
```

