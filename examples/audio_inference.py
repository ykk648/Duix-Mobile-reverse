#!/usr/bin/env python3
"""
éŸ³é¢‘ç‰¹å¾æå–æ¨ç†ç¤ºä¾‹

å®Œæ•´çš„éŸ³é¢‘åˆ°ç‰¹å¾å‘é‡æ¨ç†æµç¨‹ï¼š
1. åŠ è½½éŸ³é¢‘æ–‡ä»¶ï¼ˆWAV/PCMï¼‰
2. æå– MFCC ç‰¹å¾
3. WeNet ONNX æ¨ç†
4. è¾“å‡º BNF ç‰¹å¾å‘é‡

ä¾èµ–ï¼š
    pip install onnxruntime numpy librosa soundfile
"""

import numpy as np
import onnxruntime as ort
import librosa
import soundfile as sf
import sys
import os
from pathlib import Path

class WeNetInference:
    """WeNet éŸ³é¢‘ç‰¹å¾æå–æ¨ç†ç±»"""
    
    def __init__(self, model_path, melcnt=321, bnfcnt=79, num_threads=2):
        """
        åˆå§‹åŒ– WeNet ONNX æ¨ç†å¼•æ“
        
        Args:
            model_path: WeNet ONNX æ¨¡å‹æ–‡ä»¶è·¯å¾„
            melcnt: Mel ç‰¹å¾å¸§æ•°ï¼ˆé»˜è®¤ 321ï¼‰
            bnfcnt: BNF ç‰¹å¾å¸§æ•°ï¼ˆé»˜è®¤ 79ï¼‰
            num_threads: ONNX Runtime çº¿ç¨‹æ•°ï¼ˆé»˜è®¤ 2ï¼‰
        """
        self.melcnt = melcnt
        self.bnfcnt = bnfcnt
        
        # åˆå§‹åŒ– ONNX Runtime
        sess_options = ort.SessionOptions()
        sess_options.intra_op_num_threads = num_threads
        sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
        sess_options.add_session_config_entry("session.disable_prepacking", "1")
        
        # åŠ è½½æ¨¡å‹
        print(f"ğŸ“¥ åŠ è½½ WeNet æ¨¡å‹: {model_path}")
        self.session = ort.InferenceSession(
            model_path,
            sess_options=sess_options,
            providers=['CPUExecutionProvider']
        )
        
        # è·å–è¾“å…¥è¾“å‡ºä¿¡æ¯
        self.input_names = [inp.name for inp in self.session.get_inputs()]
        self.output_names = [out.name for out in self.session.get_outputs()]
        
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        print(f"   è¾“å…¥: {self.input_names}")
        print(f"   è¾“å‡º: {self.output_names}")
        
        # éªŒè¯è¾“å…¥è¾“å‡ºå½¢çŠ¶
        input_shapes = {inp.name: inp.shape for inp in self.session.get_inputs()}
        output_shapes = {out.name: out.shape for out in self.session.get_outputs()}
        print(f"   è¾“å…¥å½¢çŠ¶: {input_shapes}")
        print(f"   è¾“å‡ºå½¢çŠ¶: {output_shapes}")
    
    def extract_mfcc(self, audio_data, sample_rate=16000, n_mels=80, hop_length=160):
        """
        æå– MFCC ç‰¹å¾ï¼ˆMel é¢‘è°±ï¼‰
        
        Args:
            audio_data: éŸ³é¢‘æ•°æ®ï¼ˆnumpy arrayï¼Œfloat32ï¼‰
            sample_rate: é‡‡æ ·ç‡ï¼ˆé»˜è®¤ 16000 Hzï¼‰
            n_mels: Mel æ»¤æ³¢å™¨æ•°é‡ï¼ˆé»˜è®¤ 80ï¼‰
            hop_length: å¸§ç§»ï¼ˆé»˜è®¤ 160ï¼Œå¯¹åº” 10msï¼‰
        
        Returns:
            mel_features: Mel é¢‘è°±ç‰¹å¾ [melcnt, 80]
        """
        # ç¡®ä¿éŸ³é¢‘æ˜¯ float32 æ ¼å¼
        if audio_data.dtype != np.float32:
            audio_data = audio_data.astype(np.float32)
        
        # å½’ä¸€åŒ–åˆ° [-1, 1]
        if audio_data.max() > 1.0 or audio_data.min() < -1.0:
            audio_data = audio_data / np.max(np.abs(audio_data))
        
        # æå– Mel é¢‘è°±ç‰¹å¾
        mel_spec = librosa.feature.melspectrogram(
            y=audio_data,
            sr=sample_rate,
            n_mels=n_mels,
            hop_length=hop_length,
            n_fft=512,
            fmin=0,
            fmax=8000
        )
        
        # è½¬æ¢ä¸ºå¯¹æ•°å°ºåº¦
        mel_log = librosa.power_to_db(mel_spec, ref=np.max)
        
        # å½’ä¸€åŒ–åˆ° [0, 1] æˆ– [-1, 1]
        mel_log = (mel_log - mel_log.min()) / (mel_log.max() - mel_log.min() + 1e-8)
        
        # è½¬ç½®ï¼šä» [n_mels, time] è½¬ä¸º [time, n_mels]
        mel_features = mel_log.T
        
        return mel_features
    
    def pad_or_truncate_mel(self, mel_features, target_length):
        """
        å¡«å……æˆ–æˆªæ–­ Mel ç‰¹å¾åˆ°ç›®æ ‡é•¿åº¦
        
        Args:
            mel_features: Mel ç‰¹å¾ [time, 80]
            target_length: ç›®æ ‡é•¿åº¦ï¼ˆmelcntï¼‰
        
        Returns:
            padded_mel: å¤„ç†åçš„ Mel ç‰¹å¾ [target_length, 80]
        """
        current_length = mel_features.shape[0]
        
        if current_length < target_length:
            # å¡«å……é›¶
            pad_length = target_length - current_length
            pad = np.zeros((pad_length, 80), dtype=np.float32)
            padded_mel = np.concatenate([mel_features, pad], axis=0)
        elif current_length > target_length:
            # æˆªæ–­
            padded_mel = mel_features[:target_length]
        else:
            padded_mel = mel_features
        
        return padded_mel
    
    def infer(self, mel_features):
        """
        æ‰§è¡Œ WeNet ONNX æ¨ç†
        
        Args:
            mel_features: Mel é¢‘è°±ç‰¹å¾ [melcnt, 80]
        
        Returns:
            bnf_features: BNF ç‰¹å¾å‘é‡ [bnfcnt, 256]
        """
        # ç¡®ä¿å½¢çŠ¶æ­£ç¡®
        if mel_features.shape[0] != self.melcnt:
            mel_features = self.pad_or_truncate_mel(mel_features, self.melcnt)
        
        # å‡†å¤‡è¾“å…¥
        # speech: [1, melcnt, 80]
        speech_input = mel_features.reshape(1, self.melcnt, 80).astype(np.float32)
        
        # speech_lengths: [1]
        speech_lengths = np.array([self.melcnt], dtype=np.int32)
        
        # åˆ›å»ºè¾“å…¥å­—å…¸
        inputs = {
            self.input_names[0]: speech_input,      # speech
            self.input_names[1]: speech_lengths     # speech_lengths
        }
        
        # æ‰§è¡Œæ¨ç†
        outputs = self.session.run(self.output_names, inputs)
        
        # è·å–è¾“å‡ºï¼ˆencoder_outï¼‰
        bnf_features = outputs[0]  # [1, bnfcnt, 256]
        
        # ç§»é™¤ batch ç»´åº¦
        bnf_features = bnf_features[0]  # [bnfcnt, 256]
        
        return bnf_features
    
    def process_audio_file(self, audio_path):
        """
        å¤„ç†éŸ³é¢‘æ–‡ä»¶ï¼Œè¿”å› BNF ç‰¹å¾
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆWAV/PCMï¼‰
        
        Returns:
            bnf_features: BNF ç‰¹å¾å‘é‡ [bnfcnt, 256]
        """
        print(f"\nğŸ“» å¤„ç†éŸ³é¢‘æ–‡ä»¶: {audio_path}")
        
        # åŠ è½½éŸ³é¢‘
        try:
            audio_data, sample_rate = librosa.load(audio_path, sr=16000, mono=True)
            print(f"   é‡‡æ ·ç‡: {sample_rate} Hz")
            print(f"   æ—¶é•¿: {len(audio_data) / sample_rate:.2f} ç§’")
            print(f"   æ ·æœ¬æ•°: {len(audio_data):,}")
        except Exception as e:
            print(f"âŒ åŠ è½½éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {e}")
            return None
        
        # æå– MFCC ç‰¹å¾
        print("ğŸ” æå– MFCC ç‰¹å¾...")
        mel_features = self.extract_mfcc(audio_data, sample_rate)
        print(f"   Mel ç‰¹å¾å½¢çŠ¶: {mel_features.shape}")
        
        # å¡«å……æˆ–æˆªæ–­åˆ°ç›®æ ‡é•¿åº¦
        mel_features = self.pad_or_truncate_mel(mel_features, self.melcnt)
        print(f"   å¤„ç†å Mel ç‰¹å¾å½¢çŠ¶: {mel_features.shape}")
        
        # WeNet æ¨ç†
        print("ğŸ§  WeNet ONNX æ¨ç†...")
        bnf_features = self.infer(mel_features)
        print(f"   BNF ç‰¹å¾å½¢çŠ¶: {bnf_features.shape}")
        print(f"   BNF ç‰¹å¾èŒƒå›´: [{bnf_features.min():.4f}, {bnf_features.max():.4f}]")
        
        return bnf_features


def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 3:
        print("ç”¨æ³•: python audio_inference.py <wenet.onnx> <audio.wav> [è¾“å‡º.npy]")
        print("\nç¤ºä¾‹:")
        print("  python audio_inference.py wenet.onnx audio.wav")
        print("  python audio_inference.py wenet.onnx audio.wav output_bnf.npy")
        sys.exit(1)
    
    model_path = sys.argv[1]
    audio_path = sys.argv[2]
    output_path = sys.argv[3] if len(sys.argv) > 3 else None
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        sys.exit(1)
    
    if not os.path.exists(audio_path):
        print(f"âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
        sys.exit(1)
    
    print("=" * 60)
    print("ğŸ¤ WeNet éŸ³é¢‘ç‰¹å¾æå–æ¨ç†")
    print("=" * 60)
    
    # åˆ›å»ºæ¨ç†å¼•æ“
    try:
        wenet = WeNetInference(model_path, melcnt=321, bnfcnt=79)
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
        sys.exit(1)
    
    # å¤„ç†éŸ³é¢‘
    try:
        bnf_features = wenet.process_audio_file(audio_path)
        
        if bnf_features is not None:
            print("\nâœ… æ¨ç†æˆåŠŸï¼")
            print(f"ğŸ“Š BNF ç‰¹å¾ç»Ÿè®¡:")
            print(f"   å½¢çŠ¶: {bnf_features.shape}")
            print(f"   å‡å€¼: {bnf_features.mean():.4f}")
            print(f"   æ ‡å‡†å·®: {bnf_features.std():.4f}")
            print(f"   æœ€å°å€¼: {bnf_features.min():.4f}")
            print(f"   æœ€å¤§å€¼: {bnf_features.max():.4f}")
            
            # ä¿å­˜ç»“æœ
            if output_path:
                np.save(output_path, bnf_features)
                print(f"\nğŸ’¾ ç‰¹å¾å·²ä¿å­˜åˆ°: {output_path}")
            else:
                # é»˜è®¤è¾“å‡ºæ–‡ä»¶å
                default_output = Path(audio_path).stem + "_bnf.npy"
                np.save(default_output, bnf_features)
                print(f"\nğŸ’¾ ç‰¹å¾å·²ä¿å­˜åˆ°: {default_output}")
        else:
            print("\nâŒ æ¨ç†å¤±è´¥ï¼")
            sys.exit(1)
            
    except Exception as e:
        print(f"\nâŒ å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    
    print("\n" + "=" * 60)
    print("âœ… å®Œæˆï¼")
    print("=" * 60)


if __name__ == "__main__":
    main()

